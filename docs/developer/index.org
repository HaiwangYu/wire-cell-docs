* Developing Wire Cell Software

This manual provides guidance for people wishing to develop Wire Cell software.  It is organized by the type of developer.  The considered categories as follows:

- core ::  develop the Wire Cell Toolkit itself.
- application :: write a Wire Cell Toolkit application or to integrate Wire Cell Toolkit into a larger software system or framework.
- web :: develop the Bee front end.
- services :: development of the Wire Cell Services middleware connecting Bee to the toolkit.

The following sections focus on each type of developer.  It is recommended to read the "core" section regardless of what type of development you wish to do. 

* Core

** Overview

Before getting into details, a few high level things must be understood to develop the core WCT libraries.

*** Dependencies

The Wire Cell Toolkit (WCT) is designed to be integrated into other
applications or software systems in a flexible and straight-forward
manner.  To support that, certain "rules" must be followed when
developing the core of WCT.  This includes developing code that will
provide objects given to the WCT.

WCT provides an API based on a collection of abstract interface
classes.  In general no "bare" implementation classes may be exposed
except as subclasses of these interface classes.  The classes can be
partitioned into the following categories:

- data :: interfaces to the information on which Wire Cell operates.

- operators :: mostly functional objects that operate on data objects.

- executors :: see next section

One can think of the operators and data objects making up the "verbs"
and "nouns", respectively, of a Wire Cell "language".  

When doing "core" development on a WCT library or on an "external"
library provides WCT interface implementations, one must also access
WCT objects only through the API, with one exception.  A class in a
WCT library my directly instantiate or otherwise use a concrete
subclass that is defined in the same library.  No compile-time
dependencies between WCT implementation libraries are allowed (only
depend on WCT "iface" library and access required instances via the
=NamedFactory= method).

*** Execution model

WCT /operators/ are defined in such a way to partition the problem
space of Wire Cell at divisions and a granularity considered proper to
allow for competing implementations to be developed and to provide
beneficial parallel processing.

The operator interfaces are designed to be called in the context of
/Data Flow Programming/ (DFP) paradigm graph.  Following the DFP
paradigm allows complex Wire Cell processing to be run in a highly
parallel fashion by writing components that do not have to care much
about the complexity of parallel processing.  Some freedom is allowed
in defining the interfaces of core algorithms.  The limitation that is
levied on the implementations is that they do not violate thread
safety by accessing global state that is shared by other threads.
Ultimately an /executor/ adapter to an abstract execution model is
required.  This abstract execution model must then be implemented with
code that is aware of a specific DFP engine (eg, [[https://www.threadingbuildingblocks.org/][TBB]] or
[[https://github.com/erenon/pipeline][Boost.Pipeline]]) which takes care of scheduling and overall data flow
control.


** Compute nodes

DFP nodes are units of computation.  They are similar to subroutines, functions or classes (in fact they are classes).  Unlike these general programming structures node implementations are intentionally limited in scope in order to support the parallel, asynchronous data flow programming paradigm.  Nodes must:

- not access global, mutable state (const state is okay).
- not access local, mutable state if they run conncurrent instances.
- implement specific abstract base classes (interfaces).
- obey the Wire Cell end-of-stream (EOS) protocol.

*** Node Ports

Nodes receive input data and produce output data through something named a /port/.  A port passes data of a specific type, in exactly one direction (input to or output from the node) and via a particular mechanism.  These three characteristics: /data type/, /direction/ and /mechanism/ are tightly coupled.  In general, a port is conceptual and as it is realized in a few different ways depending on these characteristics.  Ports are made concrete in the node interface base class.

At the most fine-grained, data passes through ports as a /pointer/ (specifically a =std::shared_ptr<const IDataType>= where =IDataType= is a data model interface base class).  It needs stressing that the pointer is to constant, immutable data and this data is shared.  Its allocated memory will live on as long as it is held by at least one =shared_ptr<>=.  Node implementations must not violate this (must not bust out and don't hold the underlying raw pointer and must not use =const_cast<>=).

There are three mechanisms by which pointers, as described above, are passed through ports.  These mechanisms may work independently from each of the node's ports or may work in concert with a subset.  

The simplest mechanism is that a single pointer is passed through a node's interface.  If input, the node may immediately may access the data pointed to.  For output, the node creates a new, concrete data model object, wraps it into an appropriate =shared_ptr<>= and returns it to the caller.  

In order to implement /joining/ or /splitting/ of synchronous streams into compound parts, a fixed number of ports may be ganged together such that data is passed as a tuple of pointers (potentially with elements of differing types).  

The process of joining and splitting may need to be asynchronous.  This means a node may require any and differing numbers of data objects from multiple input ports or likewise for output.  Insertion of data to and extraction of data from a node is both asynchronous.  Depending on the nature of the nodes algorithm, typically such operations must maintain local state and thus may not safely run concurrently.  Often, such nodes may be factored out into multiple, simpler nodes.  In any case, data is passed through asynchronous by passing queues to the node for filling.

*** Node categories

Given just the preceding description an overly rich zoo of nodes could be invented.  In order to reduce complexity a subset of possible node patterns are defined.  A Wire Cell node must implement one.  The allowed categories are illustrated in the following diagram.

[[./node-categories.png]]

Each category is given a name shown in the box and a default maximum concurrency value, "c" is given.  The default value is chosen based on assumptions on the concrete implementations.  Nodes which likely must maintain mutable state are given a maximum concurrency of "1".  If implementation is likely to be stateless then a value of "N", indicating unbound concurrency, is given.  Developers of concrete node classes may change this value.  

A summary of the node categories is given in the following table.

+----------+-------------+------------+------+
|          |     in      | out        |      |
+----------+-----+-------+-----+------+------+
| Name     |  #  | type  |  #  | type | conc |
+----------+-----+-------+-----+------+------+
| source   |   0 | n/a   |    1| ptr  |    1 |
+----------+-----+-------+-----+------+------+
| sink     |   1 | ptr   |    0| n/a  |    1 |
+----------+-----+-------+-----+------+------+
| function |   1 | ptr   |    1| ptr  |    N |
+----------+-----+-------+-----+------+------+
| multiout |   1 | ptr   |    N| ptr  |    1 |
+----------+-----+-------+-----+------+------+
| join     |   1 | tuple |    1| ptr  |    N |
+----------+-----+-------+-----+------+------+
| split    |   1 | ptr   |    1| tuple|    N |
+----------+-----+-------+-----+------+------+
| hydra    |   N | ptr   |    N| ptr  |    1 |
+----------+-----+-------+-----+------+------+
#+TBLFM: 



* Application

* Web 

* Services

